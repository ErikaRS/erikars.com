---
author: ErikaRS
description: Originally published on Medium on May 11, 2018.  Source(https://pixabay.com/en/unknown-think-contemplate-thought-1769656/)  How
  do we actually do ethics? Do we ...
pubDate: '2018-05-11'
tags:
- On ErikaRS' Mind
title: "Ethics for\_humans"
---

*Originally published on Medium on May 11, 2018.*

[Source](https://pixabay.com/en/unknown-think-contemplate-thought-1769656/)

How do we actually *do* ethics? Do we choose a set of rules or principles and live by it regardless of the consequences? Do we make each choice based on what caused the best outcome, no matter what action it leads us to take? Do we do what feels right? Before saying what we ought to do — that is, defining a normative theory of ethics — we should spend some time looking at what we actually do. Any ethical theory that is incompatible with human psychology is, in my opinion, bunk. That is not to say that whatever people do is right. Rather, human capacity puts constraints on what an ethical system can ask of us. If an ethical theory, for example, were to claim that what is right is what the majority of humanity would consider right to do for some particular choice, it is a bad ethical theory. We are incapable of polling all of humanity whenever a decision comes up.

How we make moral decisions is a field of active study. A reasonably current state of the research is summarized in “[Our multi-system moral psychology: Towards a consensus view](https://www.researchgate.net/publication/252933609_Our_multi-system_moral_psychology_Towards_a_consensus_view)” ([pdf](https://cushmanlab.fas.harvard.edu/docs/cushman_young&greene_2010.pdf)). It appears that our moral judgments are strongly influenced by intuitive moral responses which generate a good or bad feelings (positive or negative affect). This view, however, is challenged by the fact that people do sometimes rely on conscious, explicit moral reasoning when presented with moral dilemmas. What we are starting to see indicates that this split may arise from the brain having multiple ways of processing moral situations. When a moral choice triggers our affective response system, we tend to see the right choice as obvious and non-negotiable. When it triggers our explicit moral reasoning, we tend to see the right choice as negotiable based on the outcomes. What causes one system to be triggered over the other can be surprisingly small, such as whether a harm is the outcome of an action or an anticipated and unavoidable side-effect of an action.

For the purpose of this essay, what is important is that we do have multiple moral reasoning systems and that in many situations we rely heavily on the affect based system. Although there may well be more than just the two systems, let’s focus on the affect based and cognitive systems, since those are the most prominent. Both systems have their strengths and limitations. The affect based system summarizes a massive amount of moral experience in a way that can be applied quickly. Like all intuitive systems it is subject to bias and to a lack of transparency in understanding how a particular conclusion was reached. The cognitive based system does a better job of showing how a conclusion was reached and can make trade-offs when situations are complex. It is limited by cognitive capacity and so ends up reasoning based on a simplified model of the situation at hand (such as what rule set applies). If the wrong simplification is applied, the results can be bad.

These empirical observations have interesting consequences for normative ethical theories. One is that, in practice, much of our moral reasoning is encoded in rules — the rules that underlie our affect based system. Yet rules do not provide the ultimate end to moral reasoning. We can override those rule base judgments with reasoning based on outcomes. Yet that system is expensive, so we cannot utilize it for every moral decision. We generally use it when the affect based rules seem inadequate, often when they provide insufficient coverage or where they are conflicting. Or to put it another way, moral reasoning tends to look deontological until it is faced with a situation where a deontological rule makes it feel wrong, in which case we tend to fall back to consequentialist reasoning.

This suggests to me that a successful ethical system should be similarly multi-tiered. Deontological rules determine what is right most of the time. When these rules produce conflicts or when we encounter situations that are not covered by the rules, we fall back to consequentialist reasoning to resolve the situation, with the goal of revising the rules based on the result. Since our rule based reasoning is implicit, it is not enough to revise our consciously held set of rules, we must embed them through experience based on consistently living the right rules, in other words, we need to develop a character which encodes the virtues we wish to live by. In short, everyone is right! Or to put it another way, deontological ethics, consequentialist ethics, and virtue ethics all get at some of the right ideas, and they all need to be extended to account for the fact that moral reasoning is a living process with feedback loops.

Another consequence of this line of reasoning is that ethical systems cannot be imposed on others, whether through force or logical reasoning. It is not until an ethical theory is internalized that it actively influences moral decision making. This is obviously true for affective moral reasoning. Because of our limited capacity, it is also true for cognitive moral reasoning although the level of internalization is not as deep.

(These are not new ideas, of course. Although I come at it from a different angle, this looks very similar to what I know of Pragmatic Ethics. At the heart of Pragmatic Ethics is the idea that our set of ethical rules is an approximation of the best ethical truth and that we should revise it based on the results of lived experience. I hope to revisit this connection more in the future.)
